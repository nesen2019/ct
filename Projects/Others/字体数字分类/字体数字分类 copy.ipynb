{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字体数字分类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建随机字体数字图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFont, ImageDraw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAGUlEQVR4nO3BMQEAAADCoPVP7WENoAAAAG4MIAABt9NlCQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FD4D11DCA30>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.zeros((32,32,3), dtype=np.uint8)\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACiUlEQVR4nNWWv2r6UBTH7y9tQtAMDtHNliDWLa31X6FUatHNzoU8gJ2cpQ/QRR18gUCgg6BP4BuILhY3O7TeQgXJkBZrc5M0/obAxcaQm/6233c65Hzu9557bk4IAP+L/vinI5HIwcEBTdMURQEATNN8eXnRNO1fttrf3xdFUZZlVVU3P7VYLGRZFkXR2SaoKIqaTCYbkh4fH3/h22g0iI6OGo2Gp4O7pyzLzmazeDwOADBNs9/vPzw8IIQQQjRNh0IhSZJubm5omgYAQAhTqZSu64Qyb29vcSGdTseTabfbmKnX6+Sz5/N5vKBUKnky5+fnmCkWi7uAu9Onp6c4rlarnqbX19c4Pjk5IVfKcRyE0KkCISRJUjQaZRgGAMAwTCwWkyQJIeQAEEKO48imYOf2Pz8/h8PhYDAYDoer1Wo7dXd3F8jRqejp6Yn4Ps1mM+cEQZVIJJbLpY/jcrkUBOEXjhRFjUYjl4tt264n4/E4qGM8Htc0Da80DKPf71cqlXQ6XalUer2eYRg4q2maMyYENZtNvGY6nfI87wJ4np9Op5hpNpsER5Zl5/O5Q6/X66OjI08smUyu12sHgxCyLOtnWqvVApZwf3+PScKkFgoFjF5eXvqQZ2dnmLy4uHBlf4ypbds4tizLx3Sz2eD4+/vbzzSTyeB4e8B3tZ3NZrM+JOA47vX11TnU19fX8fGxJ5ZOp7cvijz+rVYLNwsh1O12r66ucrlcLpcrFArlcrnb7ZqmiZlWq0VwBAAIgvDx8bEzlt56f38POqzJZBI3wUcQwkQiEcjREcMwoigqivL29ubyWiwWiqKIoujziSL8TPA8f3h4GA6HLcva29vTdf35+VlVVf9VfwFbc641B0zv/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28 at 0x7FD4D11F6C70>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_img(text, nums=1, shape=(28,28,3)):\n",
    "    img = np.random.randint(0, 255, shape, dtype=np.uint8)\n",
    "    # img = np.zeros(shape, dtype=np.uint8)\n",
    "    img = cv2.putText(img, f\"{text}\", (3, shape[1] - 3), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    return img \n",
    "\n",
    "Image.fromarray(get_img(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FontNumberDataset(Dataset):\n",
    "    def __init__(self, length=10000):\n",
    "        self.length = length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = random.randint(0, 9)\n",
    "        img = get_img(label)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray = torch.Tensor(gray)\n",
    "        # gray = gray.gray = gray.unsqueeze(0)\n",
    "        return gray, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(FontNumberDataset(), batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(FontNumberDataset(), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建PyTorch模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 15.041494  [   64/10000]\n",
      "loss: 0.000084  [ 6464/10000]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000055 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.000065  [   64/10000]\n",
      "loss: 0.000042  [ 6464/10000]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.000029  [   64/10000]\n",
      "loss: 0.000024  [ 6464/10000]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000022 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.000028  [   64/10000]\n",
      "loss: 0.000017  [ 6464/10000]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000017 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.000017  [   64/10000]\n",
      "loss: 0.000014  [ 6464/10000]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.000014 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 28, 28]) torch.float32 cuda:0\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    print(X.shape, X.dtype, X.device)\n",
    "    model.to(device)\n",
    "    model(X)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28]) torch.float32 cuda:0\n",
      "tensor([[ -1.5497,   4.5030,  27.1888,   9.1045,   5.2616,  -9.5313,  -9.1962,\n",
      "          -4.2608,   1.4995, -11.2393]], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "img = get_img(2)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "x = torch.from_numpy(np.array(gray, dtype=np.float32))\n",
    "x = x.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "x = x.to(device)\n",
    "model = model.to(device)\n",
    "print(x.shape, x.dtype, x.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    print(pred)\n",
    "    print(pred.argmax(0))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     pred = model(x)\n",
    "#     predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "#     print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -8.8725,  11.9386,  -8.7435,   5.2936,  30.6889, -11.4903,   4.4722,\n",
      "          -8.8027,   4.3273, -19.7141],\n",
      "        [-15.8076,  -0.2604,   6.4080,   3.3670,   6.6223,   4.7061,  -7.0685,\n",
      "         -19.8030,  24.5226, -17.5172],\n",
      "        [-15.8076,  -0.2604,   6.4080,   3.3670,   6.6223,   4.7061,  -7.0685,\n",
      "         -19.8030,  24.5226, -17.5172],\n",
      "        [ 19.3589,   3.8042,   4.2098,   5.3977,   2.7096,   2.3371,  -8.1925,\n",
      "         -16.8462,   8.4869, -12.1564]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>) tensor([4, 8, 8, 0], device='cuda:0')\n",
      "tensor([True, True, True, True], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tdata = DataLoader(FontNumberDataset(4), batch_size=4, shuffle=True)\n",
    "\n",
    "for batch, (X, y) in enumerate(tdata):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    print(pred, y)\n",
    "\n",
    "    print(pred.argmax(1) == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4238c57844cc908b76449bc4ddf9899590ca8e7952f36c82afaad1c379a56db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
